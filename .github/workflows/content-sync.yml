#
# Copying instructions
#
# the STACK must be the cloud formation stack that created the S3 bucket and distribution
#

name: Sync content with S3

on:
  workflow_call:
    inputs:
      STACK:
        required: true
        type: string

env:
  AWS_ACCOUNT: ${{ vars.HELLO_PROD_AWS }} # set at org level 

jobs:
  # GitHub-Slack app sends a workflow status message with live updates to #content-* channel
  sync:
    name: Upload to Amazon S3
    runs-on: ubuntu-24.04
    permissions:
      id-token: write
      contents: read
    steps:

      - name: Build role name
        run: |
          # Use shell string manipulation to extract the repository name
          REPO_NAME="${GITHUB_REPOSITORY#*/}"
          ROLE_NAME="arn:aws:iam::${AWS_ACCOUNT}:role/${REPO_NAME}-repo"
          # Set the environment variable for future steps
          echo "ROLE_NAME=${ROLE_NAME}" >> $GITHUB_ENV

      - name: Configure web-sync AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          role-to-assume: ${{ env.ROLE_NAME }} 
          aws-region: us-west-2

      - name: Checkout
        uses: actions/checkout@v2

      - name: Install modules and cache
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Restore npm cache
        run: npm ci

      - name: Build content
        run: npm run build

      - name: Copy S3 dir to S3 bucket with the AWS CLI
        run: |
          BUCKET_NAME=$(aws cloudformation describe-stacks --stack-name ${{ inputs.STACK }} --query 'Stacks[0].Outputs[?OutputKey==`BucketNameOutput`].OutputValue' --output text)

          # First sync everything
          # --delete is important to remove files that are no longer in the source directory
          aws s3 sync S3/ s3://${BUCKET_NAME}/ --delete

          # Then re-upload only .md and .markdown files with explicit Content-Type
          aws s3 cp S3/ s3://${BUCKET_NAME}/ \
            --recursive \
            --exclude "*" \
            --include "*.md" \
            --include "*.markdown" \
            --content-type "text/plain; charset=utf-8" \
            --metadata-directive REPLACE

          # Set up redirects for testing files using x-amz-website-redirect-location
          # Redirect testing.html and testing-2.html to /testing/
          echo "" | aws s3 cp - s3://${BUCKET_NAME}/testing.html \
            --website-redirect "/testing/" \
            --content-type "text/html"
          
          echo "" | aws s3 cp - s3://${BUCKET_NAME}/testing-2.html \
            --website-redirect "/testing/" \
            --content-type "text/html"

          # Process redirects from redirects.json file if it exists
          # Format: Top-level JSON object with source paths as keys and destination paths as values
          if [ -f "redirects.json" ]; then
            echo "Processing redirects from redirects.json..."
            
            # Check if jq is available (should be on GitHub Actions runners)
            if ! command -v jq &> /dev/null; then
              echo "Error: jq is required to parse redirects.json but is not installed"
              exit 1
            fi
            
            # Parse JSON and create redirects
            redirect_count=$(jq 'length' redirects.json)
            echo "Found $redirect_count redirect(s) to process"
            
            jq -r 'to_entries[] | "\(.key)|\(.value)"' redirects.json | while IFS='|' read -r source destination; do
              if [ -n "$source" ] && [ -n "$destination" ]; then
                # Remove leading slash from source for S3 key (S3 keys don't start with /)
                s3_key="${source#/}"
                
                echo "Creating redirect: $source -> $destination"
                echo "" | aws s3 cp - "s3://${BUCKET_NAME}/${s3_key}" \
                  --website-redirect "$destination" \
                  --content-type "text/html"
              else
                echo "Warning: Skipping redirect with missing source or destination"
              fi
            done
          else
            echo "No redirects.json file found, skipping redirect setup"
          fi

      - name: Invalidate CloudFront cache
        run: |
          DISTRIBUTION_ID=$(aws cloudformation describe-stacks --stack-name ${{ inputs.STACK }} --query 'Stacks[0].Outputs[?OutputKey==`DistributionIdOutput`].OutputValue' --output text)
          aws cloudfront create-invalidation --distribution-id ${DISTRIBUTION_ID} --paths "/*"
